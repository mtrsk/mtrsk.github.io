<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Clusters on Benevides&#39; Blog</title>
    <link>https://mtrsk.github.io/tags/clusters/</link>
    <description>Recent content in Clusters on Benevides&#39; Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://mtrsk.github.io/tags/clusters/rss.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Split Brain</title>
      <link>https://mtrsk.github.io/notes/2024/split-brain/</link>
      <pubDate>Sat, 28 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://mtrsk.github.io/notes/2024/split-brain/</guid>
      <description>:ID: 582a4090-eb66-4dfd-8166-9acd3c97dcc9&#xA;Split brain means that the [BROKEN LINK: d8a1a1ff-47e6-44bc-a627-83ca8dc61ecb] is split in two (or more) parts, but both parts think they are the only remaining part of the cluster. This can lead to very bad situations when both parts of the cluster try to host the resources that are offered by the cluster. If the resource is a file system, and multiple nodes try to write to the file system simultaneously and without coordination, it may lead to corruption of the file system and the loss of data.</description>
    </item>
    <item>
      <title>Clusters</title>
      <link>https://mtrsk.github.io/notes/2024/clusters/</link>
      <pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://mtrsk.github.io/notes/2024/clusters/</guid>
      <description>:ID: d8a1a1ff-47e6-44bc-a627-83ca8dc61ecb&#xA;Different Kinds of Clusters High Availability Clusters The goal of a high availability cluster is to make sure that critical resources reach the maximum possible availability. This goal is accomplished by installing cluster software on multiple servers. This software monitors the availability of the cluster nodes, and it monitors the availability of the services that are managed by the cluster. If a server goes down, or if the resource stops, the HA cluster will notice and make sure that the resource is restarted somewhere else in the cluster, so that it can be used again after a minimal interruption.</description>
    </item>
    <item>
      <title>Stonith</title>
      <link>https://mtrsk.github.io/notes/2024/stonith/</link>
      <pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://mtrsk.github.io/notes/2024/stonith/</guid>
      <description>:ID: 789326a5-20aa-4492-acb6-1474c3c11a4a :ROAM_ALIASES: Fencing&#xA;In STONITH, specific hardware is used to terminate a node that is no longer responsive to the cluster. The idea behind STONITH is that before migrating resources to another node in the cluster, the cluster has to confirm that the node in question really is down. To do this, the cluster will send a shutdown action to the STONITH device, which will, in turn, terminate the nonresponsive node.</description>
    </item>
    <item>
      <title>Quorum</title>
      <link>https://mtrsk.github.io/notes/2024/quorum/</link>
      <pubDate>Wed, 25 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://mtrsk.github.io/notes/2024/quorum/</guid>
      <description>:ID: 42950824-228d-48d6-abec-4e18908dfca0 :EXPORT_HUGO_CATEGORIES: &amp;ldquo;DistributedSystems&amp;rdquo; :EXPORT_HUGO_TAGS: &amp;ldquo;Clusters&amp;rdquo;&#xA;Quorum means &amp;ldquo;majority&amp;rdquo;, and the idea behind quorum is easy to understand: if the [BROKEN LINK: d8a1a1ff-47e6-44bc-a627-83ca8dc61ecb] doesnâ€™t have quorum, no actions will be taken in the cluster. This by itself would offer a good solution to avoid the [BROKEN LINK: 582a4090-eb66-4dfd-8166-9acd3c97dcc9] problem.&#xA;But to make sure that it can never happen, that multiple nodes activate the same resources in the cluster, another mechanism is used as well.</description>
    </item>
  </channel>
</rss>
